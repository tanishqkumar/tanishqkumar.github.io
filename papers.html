<html>
<head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-153791322-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-153791322-1');
  </script>
    <!-- endof Global site tag (gtag.js) - Google Analytics -->



<style>
.accordion {
  background-color: #000;
  color: #fff;
  cursor: pointer;
  padding: 18px;
  width: 100%;
  border: 1px solid white;
  /* border-top: 0.1px solid black; */
  text-align: left;
  outline: none;
  font-size: 15px;
  transition: 0.4s;
}

.active, .accordion:hover {
  background-color: #000; 
}

/* panel css and js at bottom */

li.sick {
  color: rgb(38, 150, 255);
}

li.audited {
  color: rgb(52,168,83);
}

</style>




  <link rel="stylesheet" href="/static/style.css">
  <meta charset="utf-8">
  <title>Papers · Tanishq Kumar</title>
</head>
<body>
<div id="menu">
<span class="title">Tanishq Kumar</span>
<ul>
  <li><a href="/index.html">Home</a></li>
  <li><a href="/about.html">About</a></li>
  <!-- <li><a href="/culture">Culture</a></li> -->
  <!-- <li><a href="/books.html">Bookshelf</a></li> -->
  <li><a href="/essays.html">Writing</a></li>
    <!-- <li><a href="/notes.html">Notes</a></li> -->
    <!-- <li><a href="/articles.html">Articles</a></li> -->
      <li><a href="/courses.html">Courses</a>
        <li><a href="/papers.html">Research</a>
</ul>
</div>
<div id="left"></div>
<div id="content">

    <h1>Research</h1>
    <p>I work on the science of deep learning. 
    I've had the privilege of learning to do research from 
    <a href="https://scholar.google.com/citations?user=0HuMHFwAAAAJ&hl=en">Sam Gershman</a> and
     <a href="https://scholar.google.com/citations?user=Ch9iRwQAAAAJ&hl=en">Aditi Raghunathan</a>. In the last couple of months I have been 
     focused less on publishing research and more on open source deep learning projects.
    </p>
    <button class="accordion" style="width: 200px;">Research Background</button>
    <div class="panel">
      <p>
        I'm interested in understanding what <i>systems</i> centered around foundation models will look like in 5 years, 
        and how they will touch our lives in unthinkable ways. Reasoning models and computer use/software agents are two 
        nascent examples, but I think and hope that AI systems will play a more transformative role in our day to day lives
        than mere automation. My research style usually involves studying these models in a scientific way, 
        running experiments across the stack: from pretraining to evals and beyond. 
      </p>

      <p>
        My path into deep learning was a meandering one. I was taken in by multiple research communities 
        broadly studying artificial intelligence when I was an undergraduate. Two prominent ones were physicists
        studying the brain -- who think of neural networks as freshly discovered platonic objects, pure and unsullied --
         and computer systems people who like to hack and think of neural networks as graphs of 
        differentiable tensor operations nested inside GPU cores. 
        I am fortunate to have been a part of and be mentored by folks in both communities. 
      </p>

      
    </div>

      

    
    </p>

  <button class="accordion" style="width: 200px;">Papers</button>
  <div class="panel">
    <ul>
      
      <!-- <li><a href="https://arxiv.org/abs/2411.04330">Will Synthetic Data Solve the Pretraining Data Bottleneck?</a></li>
      <strong>Preprint.</strong><br><u>Tanishq Kumar*</u>, Neil Band*, Pratyush Maini, Niklas Muennighoff, Percy Liang, Alexander Rush, Aditi Raghunathan, Tatsunori Hashimoto.<br><br>
      
      <li><a href="https://arxiv.org/abs/2411.04330">Does Intelligence Predict Reliability?</a></li>
      <strong>Preprint.</strong><br><u>Tanishq Kumar</u>, Yangjun Ruan, Benjamin F. Spector, Christopher Ré, Tatsunori Hashimoto, Aditi Raghunathan.<br><br>
       -->

        
       <li><a href="https://tanishqkumar.github.io/papers.html">Overtrained Langued Models are Harder to Finetune</a></li>
       <strong>ICBINB at ICLR 2025. </strong><strong style="color: cyan;">Best Paper.</strong><br>
       <strong>SCOPE at ICLR 2025. </strong><strong style="color: cyan;">Outstanding Paper.</strong>
       <br>Jacob Mitchell Springer, Sachin Goyal, Kaiyue Wen, <u>Tanishq Kumar</u>, Xiang Yue, Sadhika Malladi, Graham Neubig, Aditi Raghunathan.<br><br>
      
      
     <li><a href="https://arxiv.org/abs/2411.04330">Scaling Laws for Precision</a></li>
      <strong>ICLR 2025. </strong><strong style="color: cyan;">Oral Award.</strong><br><u>Tanishq Kumar*</u>, Zachary Ankner*, Benjamin F. Spector, Blake Bordelon, Niklas Muennighoff, Mansheej Paul, Cengiz Pehlevan, Christopher Ré, Aditi Raghunathan.<br><br>
      
      
      <li><a href="https://arxiv.org/pdf/2411.03541v1">Do Mice Grok? Unveiling Hidden Progress in Sensory Cortex During Overtraining</a></li>
      <strong>ICLR 2025.</strong><br><u>Tanishq Kumar</u>, Blake Bordelon, Cengiz Pehlevan, Venkatesh Murthy, Samuel J. Gershman.<br><br>
      
      <li><a href="https://tanishqkumar.github.io/papers.html">Lower Data Diversity Accelerates Training: Case Studies in Synthetic Tasks</a></li>
      <strong>Preprint.</strong><br>Suhas Kotha*, Uzay Girit*, <u>Tanishq Kumar*</u>, Gaurav Ghosal, Aditi Raghunathan.<br><br>

      <li><a href="./papers.html">Asymptotic Dynamics for Delayed Feature Learning on a Toy Model</a></li>
      <strong>HiLD at ICML 2024.</strong><br>Blake Bordelon, <u>Tanishq Kumar</u>, Samuel J. Gershman, and Cengiz Pehlevan.<br><br>

      <li><a href="https://arxiv.org/pdf/2402.01089.pdf">No Free Prune: Information-Theoretic Barriers to Pruning at Initialization</a></li>
      <strong>ICML 2024.</strong><br><u>Tanishq Kumar*</u>, Kevin Luo*, Mark Sellke.<br><br>

      <li><a href="https://arxiv.org/abs/2310.06110">Grokking as the Transition from Lazy to Rich Training Dynamics</a></li>
      <strong>ICLR 2024.</strong><br><u>Tanishq Kumar</u>, Blake Bordelon, Samuel J. Gershman*, Cengiz Pehlevan*.<br><br>

      <li><a href="https://arxiv.org/abs/2211.13087">Human or Machine? Turing Tests for Vision and Language</a></li>
      <strong>Preprint.</strong><br>Mengmi Zhang, ... <u>Tanishq Kumar</u>, ... Gabriel Kreiman.<br><br>
    </ul>
  </div>





</div>

</body>


<script>
var acc = document.getElementsByClassName("accordion");
var i;

for (i = 0; i < acc.length; i++) {
  acc[i].addEventListener("click", function() {
    this.classList.toggle("active");
    var panel = this.nextElementSibling;
    if (panel.style.display === "block") {
      panel.style.display = "none";
    } else {
      panel.style.display = "block";
    }
  });
}
</script>

<style>
.panel {
  padding: 0 18px;
  background-color: black;
  color: white;
  max-height: 0;
  overflow: hidden;
  transition: max-height 0.2s ease-out;
}
</style>

<script>
var acc = document.getElementsByClassName("accordion");
var i;

for (i = 0; i < acc.length; i++) {
  acc[i].addEventListener("click", function() {
    this.classList.toggle("active");
    var panel = this.nextElementSibling;
    if (panel.style.maxHeight) {
      panel.style.maxHeight = null;
    } else {
      panel.style.maxHeight = panel.scrollHeight + "px";
    }
  });
}
</script>

</html>



